{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/bin/python2.7')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os, sys, getopt, pickle, csv, sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix, make_scorer, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble  import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import argparse\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score    \n",
    "import preprocessor as p\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ 'svm', 'naive', 'lr', 'random_forest']\n",
    "NO_OF_FOLDS = 10\n",
    "MODEL_TYPE = \"all\"\n",
    "HASH_REMOVE = None\n",
    "LABEL_ENCODING_TWITTER = {'racism':0,'sexism':1,'none':2}\n",
    "LABEL_ENCODING_FORMSPRING = {'none':0,'bully':1}\n",
    "LABEL_ENCODING_WIKI = {'none':0,'attack':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    data = pickle.load(open(get_filename(dataset), 'rb'))\n",
    "    x_text = []\n",
    "    labels = []\n",
    "    for i in range(len(data)):\n",
    "        if(HASH_REMOVE):\n",
    "            x_text.append(p.tokenize((data[i]['text']).encode('utf-8')))\n",
    "        else:\n",
    "            x_text.append(data[i]['text'])\n",
    "        labels.append(data[i]['label'])\n",
    "    if dataset == \"wiki\":\n",
    "        reduced_number_of_samples = int(len(x_text) * 0.5)\n",
    "        x_text, labels = shuffle(x_text, labels, \n",
    "            random_state=42, \n",
    "            n_samples=reduced_number_of_samples)\n",
    "        print \"WARNING: Wiki data set reduced from %d to %d number of samples!\" % (len(data), reduced_number_of_samples)\n",
    "    return x_text,labels\n",
    "\n",
    "def get_filename(dataset):\n",
    "    global N_CLASS, HASH_REMOVE, LABEL_ENCODING\n",
    "    if(dataset==\"twitter\"):\n",
    "        filename = \"data/twitter_data.pkl\"\n",
    "        N_CLASS = 3\n",
    "        LABEL_ENCODING = LABEL_ENCODING_TWITTER\n",
    "        HASH_REMOVE = False\n",
    "    elif(dataset==\"formspring\"):\n",
    "        N_CLASS = 2\n",
    "        LABEL_ENCODING = LABEL_ENCODING_FORMSPRING\n",
    "        filename = \"data/formspring_data.pkl\"\n",
    "        HASH_REMOVE = False\n",
    "    elif(dataset==\"wiki\"):\n",
    "        N_CLASS = 2\n",
    "        LABEL_ENCODING = LABEL_ENCODING_WIKI\n",
    "        filename = \"data/wiki_data.pkl\"\n",
    "        HASH_REMOVE = False\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred):\n",
    "    #dict1 = {'racism':0,'sexism':1,'none':2}\n",
    "    if(data == \"twitter\"):\n",
    "        scores = np.array([ \n",
    "                    precision_score(y_true, y_pred, average=None, labels=[2, 0, 1]), \n",
    "                    recall_score(y_true, y_pred,  average=None, labels=[2, 0, 1]),\n",
    "                    f1_score(y_true, y_pred, average=None, labels=[2, 0, 1])])\n",
    "    else:\n",
    "        scores = np.array([ \n",
    "                    precision_score(y_true, y_pred, average=None), \n",
    "                    recall_score(y_true, y_pred,  average=None),\n",
    "                    f1_score(y_true, y_pred, average=None)])\n",
    "    return scores\n",
    "    \n",
    "def print_scores(scores):\n",
    "    for i in range(N_CLASS):\n",
    "        scores_class_prec = []\n",
    "        scores_class_rec = []\n",
    "        scores_class_f1 = []\n",
    "        for foldscore in scores:\n",
    "            scores_class_prec.append(foldscore[i])\n",
    "            scores_class_rec.append(foldscore[i])\n",
    "            scores_class_f1.append(foldscore[i])\n",
    "        scores_class_prec = np.array(scores_class_prec)\n",
    "        scores_class_rec = np.array(scores_class_rec)\n",
    "        scores_class_f1 = np.array(scores_class_f1)\n",
    "        class_string = \"\"\n",
    "        for key, value in LABEL_ENCODING.items():\n",
    "            if(value == i):\n",
    "                class_string = key\n",
    "        print \"Precision Class %s (avg): %0.3f (+/- %0.3f)\" % (class_string,scores_class_prec.mean(), scores_class_prec.std() * 2)\n",
    "        print \"Recall Class %s (avg): %0.3f (+/- %0.3f)\" % (class_string,scores_class_rec.mean(), scores_class_rec.std() * 2)\n",
    "        print \"F1_score Class %s (avg): %0.3f (+/- %0.3f)\" % (class_string,scores_class_f1.mean(), scores_class_f1.std() * 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['recall' 'recall' 'recall']\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "arr.append(np.hstack(np.array([\"precision\",\"recall\",\"F1\"])))\n",
    "arr.append(np.hstack(np.array([\"precision\",\"recall\",\"F1\"])))\n",
    "arr.append(np.hstack(np.array([\"precision\",\"recall\",\"F1\"])))\n",
    "arr = np.array(arr)\n",
    "print \"%s\" % str(arr[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model(X, Y, model_type, dump_enabled=False, dump_path=\"\"):\n",
    "    print \"Model Type:\", model_type\n",
    "    kf = KFold(n_splits=NO_OF_FOLDS, random_state=42, shuffle=True)\n",
    "    scores = []\n",
    "    first_fold = True\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        Y = np.asarray(Y)\n",
    "        model = get_model(model_type)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        curr_scores = get_scores(y_test, y_pred) \n",
    "        scores.append(curr_scores)\n",
    "    print_scores(np.array(scores))\n",
    "    if dump_enabled:\n",
    "        Y = np.asarray(Y)\n",
    "        model = get_model(model_type)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                            Y, \n",
    "                                                            random_state=42, \n",
    "                                                            test_size=0.10)\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        dump_results(y_test, y_pred, (dump_path % (model_type)))\n",
    "    \n",
    "def dump_results(y_true, y_pred, dump_path):\n",
    "    pd.DataFrame(data={\n",
    "            \"y_true\": y_true,\n",
    "            \"y_pred\": y_pred\n",
    "        }).to_csv(dump_path)\n",
    "    print(\"Writter results to \\\"\" + dump_path + \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(m_type):\n",
    "    if m_type == 'lr':\n",
    "        logreg = LogisticRegression(class_weight=\"balanced\")\n",
    "    elif m_type == 'naive':\n",
    "        logreg =  MultinomialNB()\n",
    "    elif m_type == \"random_forest\":\n",
    "        logreg = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "    elif m_type == \"svm\":\n",
    "        logreg = LinearSVC(class_weight=\"balanced\")\n",
    "    else:\n",
    "        print \"ERROR: Please specify a correst model\"\n",
    "        return None\n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_text, labels, MODEL_TYPE, dump_enabled=False, dump_path=\"\"):\n",
    "    \n",
    "    if(WORD):\n",
    "        print(\"Using word based features\")\n",
    "        bow_transformer = CountVectorizer(analyzer=\"word\",max_features = 10000,stop_words='english').fit(x_text)\n",
    "        comments_bow = bow_transformer.transform(x_text)\n",
    "        tfidf_transformer = TfidfTransformer(norm = 'l2').fit(comments_bow)\n",
    "        comments_tfidf = tfidf_transformer.transform(comments_bow)\n",
    "        features = comments_tfidf\n",
    "    else: \n",
    "        print(\"Using char n-grams based features\")\n",
    "        bow_transformer = CountVectorizer(max_features = 10000, ngram_range = (1,2)).fit(x_text)\n",
    "        comments_bow = bow_transformer.transform(x_text)\n",
    "        tfidf_transformer = TfidfTransformer(norm = 'l2').fit(comments_bow)\n",
    "        comments_tfidf = tfidf_transformer.transform(comments_bow)\n",
    "        features = comments_tfidf\n",
    "    \n",
    "    if(data == \"twitter\"):\n",
    "        labels = np.array([LABEL_ENCODING_TWITTER[b] for b in labels])\n",
    "    \n",
    "    from collections import Counter\n",
    "    print(Counter(labels))\n",
    "    \n",
    "    if(MODEL_TYPE != \"all\"):\n",
    "        classification_model(features, labels, MODEL_TYPE, dump_enabled, dump_path)\n",
    "    else:\n",
    "        for model_type in models:\n",
    "            classification_model(features, labels, model_type, dump_enabled, dump_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3e5c6c14b093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"formspring\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mWORD\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Data loaded!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_TYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dumps/formspring_%s_ngrams.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-4b4d7977291c>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mx_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"wiki\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mreduced_number_of_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_text\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         x_text, labels = shuffle(x_text, labels, \n",
      "\u001b[0;31mNameError\u001b[0m: global name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "data = \"formspring\"\n",
    "WORD =  False\n",
    "x_text, labels = load_data(data) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE, True, \"dumps/formspring_%s_ngrams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using word based features\n",
      "Counter({0: 11997, 1: 776})\n",
      "Model Type: svm\n",
      "Precision Class none (avg): 0.692 (+/- 0.557)\n",
      "Recall Class none (avg): 0.692 (+/- 0.557)\n",
      "F1_score Class none (avg): 0.692 (+/- 0.557)\n",
      "Precision Class bully (avg): 0.739 (+/- 0.438)\n",
      "Recall Class bully (avg): 0.739 (+/- 0.438)\n",
      "F1_score Class bully (avg): 0.739 (+/- 0.438)\n",
      "Writter results to \"dumps/formspring_svm_wordbased.csv\"\n",
      "Model Type: naive\n",
      "Precision Class none (avg): 0.757 (+/- 0.765)\n",
      "Recall Class none (avg): 0.757 (+/- 0.765)\n",
      "F1_score Class none (avg): 0.757 (+/- 0.765)\n",
      "Precision Class bully (avg): 0.506 (+/- 0.987)\n",
      "Recall Class bully (avg): 0.506 (+/- 0.987)\n",
      "F1_score Class bully (avg): 0.506 (+/- 0.987)\n",
      "Writter results to \"dumps/formspring_naive_wordbased.csv\"\n",
      "Model Type: lr\n",
      "Precision Class none (avg): 0.691 (+/- 0.570)\n",
      "Recall Class none (avg): 0.691 (+/- 0.570)\n",
      "F1_score Class none (avg): 0.691 (+/- 0.570)\n",
      "Precision Class bully (avg): 0.779 (+/- 0.337)\n",
      "Recall Class bully (avg): 0.779 (+/- 0.337)\n",
      "F1_score Class bully (avg): 0.779 (+/- 0.337)\n",
      "Writter results to \"dumps/formspring_lr_wordbased.csv\"\n",
      "Model Type: random_forest\n",
      "Precision Class none (avg): 0.830 (+/- 0.298)\n",
      "Recall Class none (avg): 0.830 (+/- 0.298)\n",
      "F1_score Class none (avg): 0.830 (+/- 0.298)\n",
      "Precision Class bully (avg): 0.579 (+/- 0.835)\n",
      "Recall Class bully (avg): 0.579 (+/- 0.835)\n",
      "F1_score Class bully (avg): 0.579 (+/- 0.835)\n",
      "Writter results to \"dumps/formspring_random_forest_wordbased.csv\"\n"
     ]
    }
   ],
   "source": [
    "data = \"formspring\"\n",
    "WORD = True\n",
    "x_text, labels = load_data(data) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE, True, \"dumps/formspring_%s_wordbased.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using char n-grams based features\n",
      "Counter({2: 11036, 1: 3117, 0: 1937})\n",
      "Model Type: svm\n",
      "Precision Class racism (avg): 0.803 (+/- 0.141)\n",
      "Recall Class racism (avg): 0.803 (+/- 0.141)\n",
      "F1_score Class racism (avg): 0.803 (+/- 0.141)\n",
      "Precision Class sexism (avg): 0.805 (+/- 0.145)\n",
      "Recall Class sexism (avg): 0.805 (+/- 0.145)\n",
      "F1_score Class sexism (avg): 0.805 (+/- 0.145)\n",
      "Precision Class none (avg): 0.803 (+/- 0.133)\n",
      "Recall Class none (avg): 0.803 (+/- 0.133)\n",
      "F1_score Class none (avg): 0.803 (+/- 0.133)\n",
      "Writter results to \"dumps/twitter_svm_ngrams.csv\"\n",
      "Model Type: naive\n",
      "Precision Class racism (avg): 0.835 (+/- 0.119)\n",
      "Recall Class racism (avg): 0.835 (+/- 0.119)\n",
      "F1_score Class racism (avg): 0.835 (+/- 0.119)\n",
      "Precision Class sexism (avg): 0.651 (+/- 0.450)\n",
      "Recall Class sexism (avg): 0.651 (+/- 0.450)\n",
      "F1_score Class sexism (avg): 0.651 (+/- 0.450)\n",
      "Precision Class none (avg): 0.707 (+/- 0.248)\n",
      "Recall Class none (avg): 0.707 (+/- 0.248)\n",
      "F1_score Class none (avg): 0.707 (+/- 0.248)\n",
      "Writter results to \"dumps/twitter_naive_ngrams.csv\"\n",
      "Model Type: lr\n",
      "Precision Class racism (avg): 0.811 (+/- 0.119)\n",
      "Recall Class racism (avg): 0.811 (+/- 0.119)\n",
      "F1_score Class racism (avg): 0.811 (+/- 0.119)\n",
      "Precision Class sexism (avg): 0.779 (+/- 0.232)\n",
      "Recall Class sexism (avg): 0.779 (+/- 0.232)\n",
      "F1_score Class sexism (avg): 0.779 (+/- 0.232)\n",
      "Precision Class none (avg): 0.790 (+/- 0.153)\n",
      "Recall Class none (avg): 0.790 (+/- 0.153)\n",
      "F1_score Class none (avg): 0.790 (+/- 0.153)\n",
      "Writter results to \"dumps/twitter_lr_ngrams.csv\"\n",
      "Model Type: random_forest\n",
      "Precision Class racism (avg): 0.842 (+/- 0.099)\n",
      "Recall Class racism (avg): 0.842 (+/- 0.099)\n",
      "F1_score Class racism (avg): 0.842 (+/- 0.099)\n",
      "Precision Class sexism (avg): 0.736 (+/- 0.326)\n",
      "Recall Class sexism (avg): 0.736 (+/- 0.326)\n",
      "F1_score Class sexism (avg): 0.736 (+/- 0.326)\n",
      "Precision Class none (avg): 0.774 (+/- 0.180)\n",
      "Recall Class none (avg): 0.774 (+/- 0.180)\n",
      "F1_score Class none (avg): 0.774 (+/- 0.180)\n",
      "Writter results to \"dumps/twitter_random_forest_ngrams.csv\"\n"
     ]
    }
   ],
   "source": [
    "data = \"twitter\"\n",
    "WORD = False\n",
    "x_text, labels = load_data(data) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE, True, \"dumps/twitter_%s_ngrams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using word based features\n",
      "Counter({2: 11036, 1: 3117, 0: 1937})\n",
      "Model Type: svm\n",
      "Precision Class racism (avg): 0.810 (+/- 0.141)\n",
      "Recall Class racism (avg): 0.810 (+/- 0.141)\n",
      "F1_score Class racism (avg): 0.810 (+/- 0.141)\n",
      "Precision Class sexism (avg): 0.810 (+/- 0.142)\n",
      "Recall Class sexism (avg): 0.810 (+/- 0.142)\n",
      "F1_score Class sexism (avg): 0.810 (+/- 0.142)\n",
      "Precision Class none (avg): 0.809 (+/- 0.129)\n",
      "Recall Class none (avg): 0.809 (+/- 0.129)\n",
      "F1_score Class none (avg): 0.809 (+/- 0.129)\n",
      "Writter results to \"dumps/twitter_svm_wordbased.csv\"\n",
      "Model Type: naive\n",
      "Precision Class racism (avg): 0.836 (+/- 0.109)\n",
      "Recall Class racism (avg): 0.836 (+/- 0.109)\n",
      "F1_score Class racism (avg): 0.836 (+/- 0.109)\n",
      "Precision Class sexism (avg): 0.654 (+/- 0.443)\n",
      "Recall Class sexism (avg): 0.654 (+/- 0.443)\n",
      "F1_score Class sexism (avg): 0.654 (+/- 0.443)\n",
      "Precision Class none (avg): 0.710 (+/- 0.242)\n",
      "Recall Class none (avg): 0.710 (+/- 0.242)\n",
      "F1_score Class none (avg): 0.710 (+/- 0.242)\n",
      "Writter results to \"dumps/twitter_naive_wordbased.csv\"\n",
      "Model Type: lr\n",
      "Precision Class racism (avg): 0.816 (+/- 0.121)\n",
      "Recall Class racism (avg): 0.816 (+/- 0.121)\n",
      "F1_score Class racism (avg): 0.816 (+/- 0.121)\n",
      "Precision Class sexism (avg): 0.788 (+/- 0.214)\n",
      "Recall Class sexism (avg): 0.788 (+/- 0.214)\n",
      "F1_score Class sexism (avg): 0.788 (+/- 0.214)\n",
      "Precision Class none (avg): 0.798 (+/- 0.145)\n",
      "Recall Class none (avg): 0.798 (+/- 0.145)\n",
      "F1_score Class none (avg): 0.798 (+/- 0.145)\n",
      "Writter results to \"dumps/twitter_lr_wordbased.csv\"\n",
      "Model Type: random_forest\n",
      "Precision Class racism (avg): 0.835 (+/- 0.105)\n",
      "Recall Class racism (avg): 0.835 (+/- 0.105)\n",
      "F1_score Class racism (avg): 0.835 (+/- 0.105)\n",
      "Precision Class sexism (avg): 0.773 (+/- 0.251)\n",
      "Recall Class sexism (avg): 0.773 (+/- 0.251)\n",
      "F1_score Class sexism (avg): 0.773 (+/- 0.251)\n",
      "Precision Class none (avg): 0.798 (+/- 0.150)\n",
      "Recall Class none (avg): 0.798 (+/- 0.150)\n",
      "F1_score Class none (avg): 0.798 (+/- 0.150)\n",
      "Writter results to \"dumps/twitter_random_forest_wordbased.csv\"\n"
     ]
    }
   ],
   "source": [
    "data = \"twitter\"\n",
    "WORD = True\n",
    "x_text, labels = load_data(data) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE, True, \"dumps/twitter_%s_wordbased.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Wiki data set reduced from 115864 to 57932 number of samples!\n",
      "Data loaded!\n",
      "Using char n-grams based features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 51149, 1: 6783})\n",
      "Model Type: svm\n",
      "Precision Class none (avg): 0.787 (+/- 0.366)\n",
      "Recall Class none (avg): 0.787 (+/- 0.366)\n",
      "F1_score Class none (avg): 0.787 (+/- 0.366)\n",
      "Precision Class attack (avg): 0.858 (+/- 0.151)\n",
      "Recall Class attack (avg): 0.858 (+/- 0.151)\n",
      "F1_score Class attack (avg): 0.858 (+/- 0.151)\n",
      "Writter results to \"dumps/wiki_svm_ngrams.csv\"\n",
      "Model Type: naive\n",
      "Precision Class none (avg): 0.901 (+/- 0.078)\n",
      "Recall Class none (avg): 0.901 (+/- 0.078)\n",
      "F1_score Class none (avg): 0.901 (+/- 0.078)\n",
      "Precision Class attack (avg): 0.752 (+/- 0.476)\n",
      "Recall Class attack (avg): 0.752 (+/- 0.476)\n",
      "F1_score Class attack (avg): 0.752 (+/- 0.476)\n",
      "Writter results to \"dumps/wiki_naive_ngrams.csv\"\n",
      "Model Type: lr\n",
      "Precision Class none (avg): 0.789 (+/- 0.374)\n",
      "Recall Class none (avg): 0.789 (+/- 0.374)\n",
      "F1_score Class none (avg): 0.789 (+/- 0.374)\n",
      "Precision Class attack (avg): 0.877 (+/- 0.104)\n",
      "Recall Class attack (avg): 0.877 (+/- 0.104)\n",
      "F1_score Class attack (avg): 0.877 (+/- 0.104)\n",
      "Writter results to \"dumps/wiki_lr_ngrams.csv\"\n",
      "Model Type: random_forest\n",
      "Precision Class none (avg): 0.919 (+/- 0.047)\n",
      "Recall Class none (avg): 0.919 (+/- 0.047)\n",
      "F1_score Class none (avg): 0.919 (+/- 0.047)\n",
      "Precision Class attack (avg): 0.757 (+/- 0.471)\n",
      "Recall Class attack (avg): 0.757 (+/- 0.471)\n",
      "F1_score Class attack (avg): 0.757 (+/- 0.471)\n",
      "Writter results to \"dumps/wiki_random_forest_ngrams.csv\"\n"
     ]
    }
   ],
   "source": [
    "data = \"wiki\"\n",
    "WORD = False\n",
    "x_text, labels = load_data(data) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE, True, \"dumps/wiki_%s_ngrams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Wiki data set reduced from 115864 to 57932 number of samples!\n",
      "Data loaded!\n",
      "Using word based features\n",
      "Counter({0: 51149, 1: 6783})\n",
      "Model Type: svm\n",
      "Precision Class none (avg): 0.788 (+/- 0.366)\n",
      "Recall Class none (avg): 0.788 (+/- 0.366)\n",
      "F1_score Class none (avg): 0.788 (+/- 0.366)\n",
      "Precision Class attack (avg): 0.859 (+/- 0.148)\n",
      "Recall Class attack (avg): 0.859 (+/- 0.148)\n",
      "F1_score Class attack (avg): 0.859 (+/- 0.148)\n",
      "Writter results to \"dumps/wiki_svm_wordbased.csv\"\n",
      "Model Type: naive\n",
      "Precision Class none (avg): 0.927 (+/- 0.022)\n",
      "Recall Class none (avg): 0.927 (+/- 0.022)\n",
      "F1_score Class none (avg): 0.927 (+/- 0.022)\n",
      "Precision Class attack (avg): 0.738 (+/- 0.514)\n",
      "Recall Class attack (avg): 0.738 (+/- 0.514)\n",
      "F1_score Class attack (avg): 0.738 (+/- 0.514)\n",
      "Writter results to \"dumps/wiki_naive_wordbased.csv\"\n",
      "Model Type: lr\n",
      "Precision Class none (avg): 0.798 (+/- 0.352)\n",
      "Recall Class none (avg): 0.798 (+/- 0.352)\n",
      "F1_score Class none (avg): 0.798 (+/- 0.352)\n",
      "Precision Class attack (avg): 0.873 (+/- 0.125)\n",
      "Recall Class attack (avg): 0.873 (+/- 0.125)\n",
      "F1_score Class attack (avg): 0.873 (+/- 0.125)\n",
      "Writter results to \"dumps/wiki_lr_wordbased.csv\"\n",
      "Model Type: random_forest\n",
      "Precision Class none (avg): 0.883 (+/- 0.147)\n",
      "Recall Class none (avg): 0.883 (+/- 0.147)\n",
      "F1_score Class none (avg): 0.883 (+/- 0.147)\n",
      "Precision Class attack (avg): 0.817 (+/- 0.326)\n",
      "Recall Class attack (avg): 0.817 (+/- 0.326)\n",
      "F1_score Class attack (avg): 0.817 (+/- 0.326)\n",
      "Writter results to \"dumps/wiki_random_forest_wordbased.csv\"\n"
     ]
    }
   ],
   "source": [
    "data = \"wiki\"\n",
    "WORD = True\n",
    "x_text, labels = load_data(data) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE, True, \"dumps/wiki_%s_wordbased.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d00281ea772942db40b05b5b7f3394a1f0c0f473f510a1c8681664b48ba3c89d"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
