{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/bin/python2.7')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os, sys, getopt, pickle, csv, sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix, make_scorer, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble  import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import argparse\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score    \n",
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [ 'svm', 'naive', 'lr', 'random_forest']\n",
    "NO_OF_FOLDS = 10\n",
    "MODEL_TYPE = \"all\"\n",
    "HASH_REMOVE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = pickle.load(open(filename, 'rb'))\n",
    "    x_text = []\n",
    "    labels = []\n",
    "    for i in range(len(data)):\n",
    "        if(HASH_REMOVE):\n",
    "            x_text.append(p.tokenize((data[i]['text']).encode('utf-8')))\n",
    "        else:\n",
    "            x_text.append(data[i]['text'])\n",
    "        labels.append(data[i]['label'])\n",
    "    return x_text,labels\n",
    "\n",
    "def get_filename(dataset):\n",
    "    global N_CLASS, HASH_REMOVE\n",
    "    if(dataset==\"twitter\"):\n",
    "        filename = \"data/twitter_data.pkl\"\n",
    "        N_CLASS = 3\n",
    "        HASH_REMOVE = False\n",
    "    elif(dataset==\"formspring\"):\n",
    "        N_CLASS = 2\n",
    "        filename = \"data/formspring_data.pkl\"\n",
    "        HASH_REMOVE = False\n",
    "    elif(dataset==\"wiki\"):\n",
    "        N_CLASS = 2\n",
    "        filename = \"data/wiki_data.pkl\"\n",
    "        HASH_REMOVE = False\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred):\n",
    "#     if(data==\"wiki\"):\n",
    "#         auc = roc_auc_score(y_true,y_pred)\n",
    "#         print('Test ROC AUC: %.3f' %auc)\n",
    "#     print(\":: Confusion Matrix\")\n",
    "#     print(confusion_matrix(y_true, y_pred))\n",
    "#     print(\":: Classification Report\")\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "    return np.array([ \n",
    "            precision_score(y_true, y_pred, average=None), \n",
    "            recall_score(y_true, y_pred,  average=None),\n",
    "            f1_score(y_true, y_pred, average=None)])\n",
    "    \n",
    "def print_scores(scores):\n",
    "    for i in range(N_CLASS):\n",
    "        if(i!=0):\n",
    "            print \"Precision Class %d (avg): %0.3f (+/- %0.3f)\" % (i,scores[:, i].mean(), scores[:, i].std() * 2)\n",
    "            print \"Recall Class %d (avg): %0.3f (+/- %0.3f)\" % (i,scores[:,  N_CLASS+i].mean(), scores[:,N_CLASS+i].std() * 2)\n",
    "            print \"F1_score Class %d (avg): %0.3f (+/- %0.3f)\" % (i,scores[:, N_CLASS*2+i].mean(), scores[:,  N_CLASS*2+i].std() * 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['recall' 'recall' 'recall']\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "arr.append(np.hstack(np.array([\"precision\",\"recall\",\"F1\"])))\n",
    "arr.append(np.hstack(np.array([\"precision\",\"recall\",\"F1\"])))\n",
    "arr.append(np.hstack(np.array([\"precision\",\"recall\",\"F1\"])))\n",
    "arr = np.array(arr)\n",
    "print \"%s\" % str(arr[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_model(X, Y, model_type):\n",
    "    X, Y = shuffle(X, Y, random_state=42)\n",
    "    print \"Model Type:\", model_type\n",
    "    kf = KFold(n_splits=NO_OF_FOLDS)\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        Y = np.asarray(Y)\n",
    "        model = get_model(model_type)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        curr_scores = get_scores(y_test, y_pred) \n",
    "            #[\n",
    "            #   [precision, precision, precision], -> length == number of classes\n",
    "            #   [recall, recall, recall], \n",
    "            #   [f1, f1, f1]\n",
    "            #]\n",
    "        print(curr_scores)\n",
    "        scores.append(np.hstack(curr_scores))\n",
    "        # [\n",
    "        #   [precision, ... , precision] -> len == number of folds\n",
    "        #   [recall, ... , recall]\n",
    "        #   [f1, ... , f1]\n",
    "        # ]\n",
    "    print_scores(np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(m_type):\n",
    "    if m_type == 'lr':\n",
    "        logreg = LogisticRegression(class_weight=\"balanced\")\n",
    "    elif m_type == 'naive':\n",
    "        logreg =  MultinomialNB()\n",
    "    elif m_type == \"random_forest\":\n",
    "        logreg = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "    elif m_type == \"svm\":\n",
    "        logreg = LinearSVC(class_weight=\"balanced\")\n",
    "    else:\n",
    "        print \"ERROR: Please specify a correst model\"\n",
    "        return None\n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(x_text, labels, MODEL_TYPE):\n",
    "    \n",
    "    if(WORD):\n",
    "        print(\"Using word based features\")\n",
    "        bow_transformer = CountVectorizer(analyzer=\"word\",max_features = 10000,stop_words='english').fit(x_text)\n",
    "        comments_bow = bow_transformer.transform(x_text)\n",
    "        tfidf_transformer = TfidfTransformer(norm = 'l2').fit(comments_bow)\n",
    "        comments_tfidf = tfidf_transformer.transform(comments_bow)\n",
    "        features = comments_tfidf\n",
    "    else: \n",
    "        print(\"Using char n-grams based features\")\n",
    "        bow_transformer = CountVectorizer(max_features = 10000, ngram_range = (1,2)).fit(x_text)\n",
    "        comments_bow = bow_transformer.transform(x_text)\n",
    "        tfidf_transformer = TfidfTransformer(norm = 'l2').fit(comments_bow)\n",
    "        comments_tfidf = tfidf_transformer.transform(comments_bow)\n",
    "        features = comments_tfidf\n",
    "    \n",
    "    if(data == \"twitter\"):\n",
    "        dict1 = {'racism':0,'sexism':1,'none':2}\n",
    "        labels = np.array([dict1[b] for b in labels])\n",
    "    \n",
    "    from collections import Counter\n",
    "    print(Counter(labels))\n",
    "    \n",
    "    if(MODEL_TYPE != \"all\"):\n",
    "        classification_model(features, labels, MODEL_TYPE)\n",
    "    else:\n",
    "        for model_type in models:\n",
    "            classification_model(features, labels, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using char n-grams based features\n",
      "Counter({0: 11997, 1: 776})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.466 (+/- 0.109)\n",
      "Recall Class 1 (avg): 0.503 (+/- 0.122)\n",
      "F1_score Class 1 (avg): 0.483 (+/- 0.104)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.850 (+/- 0.640)\n",
      "Recall Class 1 (avg): 0.015 (+/- 0.015)\n",
      "F1_score Class 1 (avg): 0.030 (+/- 0.028)\n",
      "Model Type: lr\n",
      "Precision Class 1 (avg): 0.410 (+/- 0.099)\n",
      "Recall Class 1 (avg): 0.626 (+/- 0.131)\n",
      "F1_score Class 1 (avg): 0.495 (+/- 0.104)\n",
      "Model Type: random_forest\n",
      "Precision Class 1 (avg): 0.735 (+/- 0.230)\n",
      "Recall Class 1 (avg): 0.161 (+/- 0.084)\n",
      "F1_score Class 1 (avg): 0.261 (+/- 0.122)\n"
     ]
    }
   ],
   "source": [
    "data = \"formspring\"\n",
    "WORD =  False\n",
    "x_text, labels = load_data(get_filename(data)) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using word based features\n",
      "Counter({0: 11997, 1: 776})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.415 (+/- 0.089)\n",
      "Recall Class 1 (avg): 0.525 (+/- 0.132)\n",
      "F1_score Class 1 (avg): 0.463 (+/- 0.100)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.575 (+/- 0.950)\n",
      "Recall Class 1 (avg): 0.013 (+/- 0.029)\n",
      "F1_score Class 1 (avg): 0.025 (+/- 0.055)\n",
      "Model Type: lr\n",
      "Precision Class 1 (avg): 0.407 (+/- 0.079)\n",
      "Recall Class 1 (avg): 0.617 (+/- 0.127)\n",
      "F1_score Class 1 (avg): 0.489 (+/- 0.084)\n",
      "Model Type: random_forest\n",
      "Precision Class 1 (avg): 0.695 (+/- 0.264)\n",
      "Recall Class 1 (avg): 0.162 (+/- 0.067)\n",
      "F1_score Class 1 (avg): 0.261 (+/- 0.098)\n"
     ]
    }
   ],
   "source": [
    "data = \"formspring\"\n",
    "WORD = True\n",
    "x_text, labels = load_data(get_filename(data)) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using char n-grams based features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/.conda/envs/cyberbullying/lib/python2.7/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 11036, 1: 3117, 0: 1937})\n",
      "Model Type: svm\n",
      "[[0.74883721 0.79927007 0.87857143]\n",
      " [0.77777778 0.70192308 0.90275229]\n",
      " [0.76303318 0.74744027 0.89049774]]\n",
      "[[0.7092511  0.78360656 0.9090065 ]\n",
      " [0.81725888 0.79139073 0.88198198]\n",
      " [0.75943396 0.78747941 0.89529035]]\n",
      "[[0.72815534 0.82042254 0.90169794]\n",
      " [0.83798883 0.7327044  0.9073741 ]\n",
      " [0.77922078 0.77408638 0.90452712]]\n",
      "[[0.76530612 0.79931973 0.86327078]\n",
      " [0.75376884 0.6851312  0.90534208]\n",
      " [0.75949367 0.73783359 0.88380604]]\n",
      "[[0.705      0.8172043  0.89823009]\n",
      " [0.7877095  0.73786408 0.90544157]\n",
      " [0.74406332 0.7755102  0.90182141]]\n",
      "[[0.74881517 0.74914089 0.87985547]\n",
      " [0.73831776 0.72666667 0.88949772]\n",
      " [0.74352941 0.73773266 0.88465032]]\n",
      "[[0.69154229 0.74223602 0.90331492]\n",
      " [0.74731183 0.78618421 0.8766756 ]\n",
      " [0.71834625 0.76357827 0.88979592]]\n",
      "[[0.69856459 0.78368794 0.89534884]\n",
      " [0.80662983 0.71521036 0.8945487 ]\n",
      " [0.74871795 0.74788494 0.89494859]]\n",
      "[[0.73267327 0.81045752 0.89009991]\n",
      " [0.75897436 0.7654321  0.89908257]\n",
      " [0.74559194 0.78730159 0.89456869]]\n",
      "[[0.7804878  0.75357143 0.89145907]\n",
      " [0.8        0.71283784 0.90026954]\n",
      " [0.79012346 0.73263889 0.89584265]]\n",
      "Precision Class 1 (avg): 0.786 (+/- 0.055)\n",
      "Recall Class 1 (avg): 0.736 (+/- 0.067)\n",
      "F1_score Class 1 (avg): 0.759 (+/- 0.040)\n",
      "Precision Class 2 (avg): 0.891 (+/- 0.026)\n",
      "Recall Class 2 (avg): 0.896 (+/- 0.020)\n",
      "F1_score Class 2 (avg): 0.894 (+/- 0.013)\n",
      "Model Type: naive\n",
      "[[0.78082192 0.91176471 0.78824416]\n",
      " [0.55072464 0.3974359  0.95963303]\n",
      " [0.64589235 0.55357143 0.86553579]]\n",
      "[[0.76388889 0.93037975 0.81484315]\n",
      " [0.55837563 0.48675497 0.95945946]\n",
      " [0.64516129 0.63913043 0.88125776]]\n",
      "[[0.82307692 0.90972222 0.80599251]\n",
      " [0.59776536 0.41194969 0.9676259 ]\n",
      " [0.69255663 0.56709957 0.87944422]]\n",
      "[[0.81746032 0.9378882  0.78290469]\n",
      " [0.51758794 0.44023324 0.97000937]\n",
      " [0.63384615 0.59920635 0.86647133]]\n",
      "[[0.76724138 0.90566038 0.80884558]\n",
      " [0.4972067  0.46601942 0.96253345]\n",
      " [0.60338983 0.61538462 0.8790224 ]]\n",
      "[[0.7972028  0.9        0.7993921 ]\n",
      " [0.53271028 0.45       0.96073059]\n",
      " [0.63865546 0.6        0.87266694]]\n",
      "[[0.7704918  0.90374332 0.82846154]\n",
      " [0.50537634 0.55592105 0.96246649]\n",
      " [0.61038961 0.68839104 0.8904506 ]]\n",
      "[[0.73880597 0.9044586  0.81259484]\n",
      " [0.54696133 0.45954693 0.95710456]\n",
      " [0.62857143 0.60944206 0.87894953]]\n",
      "[[0.79259259 0.95652174 0.80426504]\n",
      " [0.54871795 0.47530864 0.96880734]\n",
      " [0.64848485 0.63505155 0.87890137]]\n",
      "[[0.85       0.84397163 0.79599407]\n",
      " [0.51       0.40202703 0.9640611 ]\n",
      " [0.6375     0.54462243 0.87200325]]\n",
      "Precision Class 1 (avg): 0.910 (+/- 0.056)\n",
      "Recall Class 1 (avg): 0.455 (+/- 0.089)\n",
      "F1_score Class 1 (avg): 0.605 (+/- 0.082)\n",
      "Precision Class 2 (avg): 0.804 (+/- 0.025)\n",
      "Recall Class 2 (avg): 0.963 (+/- 0.008)\n",
      "F1_score Class 2 (avg): 0.876 (+/- 0.014)\n",
      "Model Type: lr\n",
      "[[0.76851852 0.84090909 0.85848252]\n",
      " [0.80193237 0.59294872 0.92385321]\n",
      " [0.78486998 0.69548872 0.88996907]]\n",
      "[[0.70720721 0.84738956 0.8857645 ]\n",
      " [0.79695431 0.6986755  0.90810811]\n",
      " [0.74940334 0.76588022 0.89679715]]\n",
      "[[0.74396135 0.83467742 0.88388215]\n",
      " [0.8603352  0.6509434  0.91726619]\n",
      " [0.79792746 0.73144876 0.90026478]]\n",
      "[[0.7761194  0.82591093 0.84409991]\n",
      " [0.7839196  0.59475219 0.91846298]\n",
      " [0.78       0.69152542 0.87971275]]\n",
      "[[0.69633508 0.8558952  0.86627418]\n",
      " [0.74301676 0.63430421 0.91882248]\n",
      " [0.71891892 0.72862454 0.89177489]]\n",
      "[[0.75813953 0.82173913 0.86340206]\n",
      " [0.76168224 0.63       0.91780822]\n",
      " [0.75990676 0.71320755 0.88977424]]\n",
      "[[0.70408163 0.79335793 0.88441331]\n",
      " [0.74193548 0.70723684 0.9025916 ]\n",
      " [0.72251309 0.74782609 0.89341   ]]\n",
      "[[0.705      0.81481481 0.87307033]\n",
      " [0.77900552 0.6407767  0.90974084]\n",
      " [0.74015748 0.7173913  0.89102845]]\n",
      "[[0.75609756 0.84351145 0.87478109]\n",
      " [0.79487179 0.68209877 0.91651376]\n",
      " [0.775      0.75426621 0.89516129]]\n",
      "[[0.75757576 0.77477477 0.85534062]\n",
      " [0.75       0.58108108 0.91374663]\n",
      " [0.75376884 0.66409266 0.8835795 ]]\n",
      "Precision Class 1 (avg): 0.825 (+/- 0.048)\n",
      "Recall Class 1 (avg): 0.641 (+/- 0.084)\n",
      "F1_score Class 1 (avg): 0.721 (+/- 0.059)\n",
      "Precision Class 2 (avg): 0.869 (+/- 0.026)\n",
      "Recall Class 2 (avg): 0.915 (+/- 0.012)\n",
      "F1_score Class 2 (avg): 0.891 (+/- 0.011)\n",
      "Model Type: random_forest\n",
      "[[0.79289941 0.9273743  0.82712133]\n",
      " [0.647343   0.53205128 0.95688073]\n",
      " [0.71276596 0.67617108 0.88728201]]\n",
      "[[0.78651685 0.93203883 0.86367347]\n",
      " [0.7106599  0.63576159 0.95315315]\n",
      " [0.74666667 0.75590551 0.90620985]]\n",
      "[[0.78285714 0.93333333 0.85714286]\n",
      " [0.76536313 0.57232704 0.95503597]\n",
      " [0.7740113  0.70955166 0.90344534]]\n",
      "[[0.8164557  0.88541667 0.80698967]\n",
      " [0.64824121 0.49562682 0.95220244]\n",
      " [0.72268908 0.63551402 0.87360275]]\n",
      "[[0.72619048 0.91089109 0.85310734]\n",
      " [0.68156425 0.59546926 0.94290812]\n",
      " [0.70317003 0.72015656 0.89576271]]\n",
      "[[0.79428571 0.89502762 0.83080607]\n",
      " [0.64953271 0.54       0.95068493]\n",
      " [0.71465296 0.67359667 0.8867121 ]]\n",
      "[[0.74556213 0.89671362 0.8590057 ]\n",
      " [0.67741935 0.62828947 0.94191242]\n",
      " [0.70985915 0.73887814 0.89855072]]\n",
      "[[0.72352941 0.88       0.84826473]\n",
      " [0.67955801 0.56957929 0.93923146]\n",
      " [0.7008547  0.69155206 0.89143342]]\n",
      "[[0.80813953 0.89320388 0.8415922 ]\n",
      " [0.71282051 0.56790123 0.95045872]\n",
      " [0.75749319 0.69433962 0.89271866]]\n",
      "[[0.87898089 0.82887701 0.84031621]\n",
      " [0.69       0.52364865 0.95507637]\n",
      " [0.77310924 0.64182195 0.8940286 ]]\n",
      "Precision Class 1 (avg): 0.898 (+/- 0.059)\n",
      "Recall Class 1 (avg): 0.566 (+/- 0.085)\n",
      "F1_score Class 1 (avg): 0.694 (+/- 0.074)\n",
      "Precision Class 2 (avg): 0.843 (+/- 0.033)\n",
      "Recall Class 2 (avg): 0.950 (+/- 0.012)\n",
      "F1_score Class 2 (avg): 0.893 (+/- 0.018)\n"
     ]
    }
   ],
   "source": [
    "data = \"twitter\"\n",
    "WORD = False\n",
    "x_text, labels = load_data(get_filename(data)) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using word based features\n",
      "Counter({2: 11036, 1: 3117, 0: 1937})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.803 (+/- 0.044)\n",
      "Recall Class 1 (avg): 0.744 (+/- 0.052)\n",
      "F1_score Class 1 (avg): 0.772 (+/- 0.037)\n",
      "Precision Class 2 (avg): 0.893 (+/- 0.023)\n",
      "Recall Class 2 (avg): 0.901 (+/- 0.018)\n",
      "F1_score Class 2 (avg): 0.897 (+/- 0.009)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.904 (+/- 0.035)\n",
      "Recall Class 1 (avg): 0.469 (+/- 0.056)\n",
      "F1_score Class 1 (avg): 0.617 (+/- 0.051)\n",
      "Precision Class 2 (avg): 0.806 (+/- 0.022)\n",
      "Recall Class 2 (avg): 0.963 (+/- 0.007)\n",
      "F1_score Class 2 (avg): 0.877 (+/- 0.011)\n",
      "Model Type: lr\n",
      "Precision Class 1 (avg): 0.832 (+/- 0.039)\n",
      "Recall Class 1 (avg): 0.663 (+/- 0.083)\n",
      "F1_score Class 1 (avg): 0.738 (+/- 0.062)\n",
      "Precision Class 2 (avg): 0.875 (+/- 0.026)\n",
      "Recall Class 2 (avg): 0.916 (+/- 0.012)\n",
      "F1_score Class 2 (avg): 0.895 (+/- 0.012)\n",
      "Model Type: random_forest\n",
      "Precision Class 1 (avg): 0.875 (+/- 0.042)\n",
      "Recall Class 1 (avg): 0.643 (+/- 0.082)\n",
      "F1_score Class 1 (avg): 0.741 (+/- 0.063)\n",
      "Precision Class 2 (avg): 0.867 (+/- 0.029)\n",
      "Recall Class 2 (avg): 0.937 (+/- 0.008)\n",
      "F1_score Class 2 (avg): 0.901 (+/- 0.016)\n"
     ]
    }
   ],
   "source": [
    "data = \"twitter\"\n",
    "WORD = True\n",
    "x_text, labels = load_data(get_filename(data)) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using char n-grams based features\n",
      "Counter({0: 102274, 1: 13590})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.591 (+/- 0.025)\n",
      "Recall Class 1 (avg): 0.823 (+/- 0.019)\n",
      "F1_score Class 1 (avg): 0.688 (+/- 0.018)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.839 (+/- 0.010)\n",
      "Recall Class 1 (avg): 0.554 (+/- 0.028)\n",
      "F1_score Class 1 (avg): 0.667 (+/- 0.021)\n",
      "Model Type: lr\n",
      "Precision Class 1 (avg): 0.602 (+/- 0.024)\n",
      "Recall Class 1 (avg): 0.845 (+/- 0.022)\n",
      "F1_score Class 1 (avg): 0.703 (+/- 0.017)\n",
      "Model Type: random_forest\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9bdb4be0efd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Data loaded!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_TYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-f5a18c7c6726>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(x_text, labels, MODEL_TYPE)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mclassification_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-42854b339f80>\u001b[0m in \u001b[0;36mclassification_model\u001b[0;34m(X, Y, model_type)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcurr_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/.conda/envs/cyberbullying/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 327\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/.conda/envs/cyberbullying/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/.conda/envs/cyberbullying/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/.conda/envs/cyberbullying/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/.conda/envs/cyberbullying/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/.conda/envs/cyberbullying/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = \"wiki\"\n",
    "WORD = False\n",
    "x_text, labels = load_data(get_filename(data)) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"wiki\"\n",
    "WORD = True\n",
    "x_text, labels = load_data(get_filename(data)) \n",
    "print (\"Data loaded!\")\n",
    "train(x_text, labels, MODEL_TYPE)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d00281ea772942db40b05b5b7f3394a1f0c0f473f510a1c8681664b48ba3c89d"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
